<!DOCTYPE html>
<html><head><title>Creanalytics</title><meta charSet="utf-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><meta property="og:title" content="Creanalytics"/><meta property="og:description" content="Creanalytics § Between Data Analysis and Media Synthesis § Dr Daniel Chávez Heras @chavezheras@sigmoid.social movingpixel.net note: Thank you for the invitation, delighted to be here."/><meta property="og:image" content="https://garden.movingpixel.net/static/og-image.png"/><meta property="og:width" content="1200"/><meta property="og:height" content="675"/><link rel="icon" href="../../static/icon.png"/><meta name="description" content="Creanalytics § Between Data Analysis and Media Synthesis § Dr Daniel Chávez Heras @chavezheras@sigmoid.social movingpixel.net note: Thank you for the invitation, delighted to be here."/><meta name="generator" content="Quartz"/><link rel="preconnect" href="https://fonts.googleapis.com"/><link rel="preconnect" href="https://fonts.gstatic.com"/><link href="../../index.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://cdn.jsdelivr.net/npm/katex@0.16.0/dist/katex.min.css" rel="stylesheet" type="text/css" spa-preserve/><link href="https://fonts.googleapis.com/css2?family=IBM Plex Mono&amp;family=Schibsted Grotesk:wght@400;700&amp;family=Source Sans Pro:ital,wght@0,400;0,600;1,400;1,600&amp;display=swap" rel="stylesheet" type="text/css" spa-preserve/><script src="../../prescript.js" type="application/javascript" spa-preserve></script><script type="application/javascript" spa-preserve>const fetchData = fetch(`../../static/contentIndex.json`).then(data => data.json())</script></head><body data-slug="public_notes/EPFL-symposium/Creanalytics"><div id="quartz-root" class="page"><div id="quartz-body"><div class="left sidebar"><h1 class="page-title "><a href="../..">📝 Daniel's Notes</a></h1><div class="spacer mobile-only"></div><div class="search "><div id="search-icon"><p>Search</p><div></div><svg tabIndex="0" aria-labelledby="title desc" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 19.9 19.7"><title id="title">Search</title><desc id="desc">Search</desc><g class="search-path" fill="none"><path stroke-linecap="square" d="M18.5 18.3l-5.4-5.4"></path><circle cx="8" cy="8" r="7"></circle></g></svg></div><div id="search-container"><div id="search-space"><input autocomplete="off" id="search-bar" name="search" type="text" aria-label="Search for something" placeholder="Search for something"/><div id="results-container"></div></div></div></div><div class="darkmode "><input class="toggle" id="darkmode-toggle" type="checkbox" tabIndex="-1"/><label id="toggle-label-light" for="darkmode-toggle" tabIndex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" version="1.1" id="dayIcon" x="0px" y="0px" viewBox="0 0 35 35" style="enable-background:new 0 0 35 35;" xmlSpace="preserve"><title>Light mode</title><path d="M6,17.5C6,16.672,5.328,16,4.5,16h-3C0.672,16,0,16.672,0,17.5    S0.672,19,1.5,19h3C5.328,19,6,18.328,6,17.5z M7.5,26c-0.414,0-0.789,0.168-1.061,0.439l-2,2C4.168,28.711,4,29.086,4,29.5    C4,30.328,4.671,31,5.5,31c0.414,0,0.789-0.168,1.06-0.44l2-2C8.832,28.289,9,27.914,9,27.5C9,26.672,8.329,26,7.5,26z M17.5,6    C18.329,6,19,5.328,19,4.5v-3C19,0.672,18.329,0,17.5,0S16,0.672,16,1.5v3C16,5.328,16.671,6,17.5,6z M27.5,9    c0.414,0,0.789-0.168,1.06-0.439l2-2C30.832,6.289,31,5.914,31,5.5C31,4.672,30.329,4,29.5,4c-0.414,0-0.789,0.168-1.061,0.44    l-2,2C26.168,6.711,26,7.086,26,7.5C26,8.328,26.671,9,27.5,9z M6.439,8.561C6.711,8.832,7.086,9,7.5,9C8.328,9,9,8.328,9,7.5    c0-0.414-0.168-0.789-0.439-1.061l-2-2C6.289,4.168,5.914,4,5.5,4C4.672,4,4,4.672,4,5.5c0,0.414,0.168,0.789,0.439,1.06    L6.439,8.561z M33.5,16h-3c-0.828,0-1.5,0.672-1.5,1.5s0.672,1.5,1.5,1.5h3c0.828,0,1.5-0.672,1.5-1.5S34.328,16,33.5,16z     M28.561,26.439C28.289,26.168,27.914,26,27.5,26c-0.828,0-1.5,0.672-1.5,1.5c0,0.414,0.168,0.789,0.439,1.06l2,2    C28.711,30.832,29.086,31,29.5,31c0.828,0,1.5-0.672,1.5-1.5c0-0.414-0.168-0.789-0.439-1.061L28.561,26.439z M17.5,29    c-0.829,0-1.5,0.672-1.5,1.5v3c0,0.828,0.671,1.5,1.5,1.5s1.5-0.672,1.5-1.5v-3C19,29.672,18.329,29,17.5,29z M17.5,7    C11.71,7,7,11.71,7,17.5S11.71,28,17.5,28S28,23.29,28,17.5S23.29,7,17.5,7z M17.5,25c-4.136,0-7.5-3.364-7.5-7.5    c0-4.136,3.364-7.5,7.5-7.5c4.136,0,7.5,3.364,7.5,7.5C25,21.636,21.636,25,17.5,25z"></path></svg></label><label id="toggle-label-dark" for="darkmode-toggle" tabIndex="-1"><svg xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" version="1.1" id="nightIcon" x="0px" y="0px" viewBox="0 0 100 100" style="enable-background='new 0 0 100 100'" xmlSpace="preserve"><title>Dark mode</title><path d="M96.76,66.458c-0.853-0.852-2.15-1.064-3.23-0.534c-6.063,2.991-12.858,4.571-19.655,4.571  C62.022,70.495,50.88,65.88,42.5,57.5C29.043,44.043,25.658,23.536,34.076,6.47c0.532-1.08,0.318-2.379-0.534-3.23  c-0.851-0.852-2.15-1.064-3.23-0.534c-4.918,2.427-9.375,5.619-13.246,9.491c-9.447,9.447-14.65,22.008-14.65,35.369  c0,13.36,5.203,25.921,14.65,35.368s22.008,14.65,35.368,14.65c13.361,0,25.921-5.203,35.369-14.65  c3.872-3.871,7.064-8.328,9.491-13.246C97.826,68.608,97.611,67.309,96.76,66.458z"></path></svg></label></div><div class="explorer desktop-only"><button type="button" id="explorer" data-behavior="collapse" data-collapsed="collapsed" data-savestate="true" data-tree="[{&quot;path&quot;:&quot;home&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive/Academic&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive/Academic/Research&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive/Academic/Research/Publications&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive/Academic/Research/Publications/first_cow&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV/data&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV/data/shots&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV/data/shots/stills&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/EINA&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/EPFL symposium&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/creanalytics&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/creanalytics/plugin&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/creanalytics/plugin/chalkboard&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/creanalytics/plugin/chart&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/creanalytics/plugin/customcontrols&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/creanalytics/plugin/menu&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/EINA conference&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/EINA conference/plugin&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/EINA conference/plugin/chalkboard&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/EINA conference/plugin/chart&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/EINA conference/plugin/customcontrols&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/export/EINA conference/plugin/menu&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/Sculpting Time with Computers&quot;,&quot;collapsed&quot;:true},{&quot;path&quot;:&quot;public_notes/Tools&quot;,&quot;collapsed&quot;:true}]"><h1>Explorer</h1><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="explorer-content"><ul class="overflow" id="explorer-ul"><li><div><div class="folder-outer open"><ul style="padding-left:0;" class="content" data-folderul><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home"><button class="folder-button"><p class="folder-title">home</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel"><button class="folder-button"><p class="folder-title">daniel</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive"><button class="folder-button"><p class="folder-title">OneDrive</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive/Academic"><button class="folder-button"><p class="folder-title">Academic</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive/Academic"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive/Academic/Research"><button class="folder-button"><p class="folder-title">Research</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive/Academic/Research"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive/Academic/Research/Publications"><button class="folder-button"><p class="folder-title">Publications</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive/Academic/Research/Publications"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive/Academic/Research/Publications/first_cow"><button class="folder-button"><p class="folder-title">first_cow</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive/Academic/Research/Publications/first_cow"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision"><button class="folder-button"><p class="folder-title">Cinema and Machine Vision</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects"><button class="folder-button"><p class="folder-title">projects</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV"><button class="folder-button"><p class="folder-title">DV</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV/data"><button class="folder-button"><p class="folder-title">data</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV/data"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV/data/shots"><button class="folder-button"><p class="folder-title">shots</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV/data/shots"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV/data/shots/stills"><button class="folder-button"><p class="folder-title">stills</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema and Machine Vision/projects/DV/data/shots/stills"><li><li><a href="../../home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema-and-Machine-Vision/projects/DV/data/shots/stills/godfather-Scene-1365-03.jpg" data-for="home/daniel/OneDrive/Academic/Research/Publications/first_cow/Cinema-and-Machine-Vision/projects/DV/data/shots/stills/godfather-Scene-1365-03.jpg">godfather-Scene-1365-03.jpg</a></li></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes"><button class="folder-button"><p class="folder-title">public_notes</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/EINA"><button class="folder-button"><p class="folder-title">EINA conference</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/EINA"></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/EPFL symposium"><button class="folder-button"><p class="folder-title">EPFL symposium</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/EPFL symposium"><li><li><a href="../../public_notes/EPFL-symposium/Creanalytics" data-for="public_notes/EPFL-symposium/Creanalytics">Creanalytics</a></li></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export"><button class="folder-button"><p class="folder-title">export</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/creanalytics"><button class="folder-button"><p class="folder-title">creanalytics</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/creanalytics"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/creanalytics/plugin"><button class="folder-button"><p class="folder-title">plugin</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/creanalytics/plugin"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/creanalytics/plugin/chalkboard"><button class="folder-button"><p class="folder-title">chalkboard</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/creanalytics/plugin/chalkboard"><li><li><a href="../../public_notes/export/creanalytics/plugin/chalkboard/README" data-for="public_notes/export/creanalytics/plugin/chalkboard/README">README</a></li></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/creanalytics/plugin/chart"><button class="folder-button"><p class="folder-title">chart</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/creanalytics/plugin/chart"><li><li><a href="../../public_notes/export/creanalytics/plugin/chart/README" data-for="public_notes/export/creanalytics/plugin/chart/README">README</a></li></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/creanalytics/plugin/customcontrols"><button class="folder-button"><p class="folder-title">customcontrols</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/creanalytics/plugin/customcontrols"><li><li><a href="../../public_notes/export/creanalytics/plugin/customcontrols/README" data-for="public_notes/export/creanalytics/plugin/customcontrols/README">README</a></li></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/creanalytics/plugin/menu"><button class="folder-button"><p class="folder-title">menu</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/creanalytics/plugin/menu"><li><li><a href="../../public_notes/export/creanalytics/plugin/menu/CONTRIBUTING" data-for="public_notes/export/creanalytics/plugin/menu/CONTRIBUTING">CONTRIBUTING</a></li></li><li><li><a href="../../public_notes/export/creanalytics/plugin/menu/README" data-for="public_notes/export/creanalytics/plugin/menu/README">README</a></li></li></ul></div></div></li></ul></div></div></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/EINA conference"><button class="folder-button"><p class="folder-title">EINA conference</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/EINA conference"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/EINA conference/plugin"><button class="folder-button"><p class="folder-title">plugin</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/EINA conference/plugin"><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/EINA conference/plugin/chalkboard"><button class="folder-button"><p class="folder-title">chalkboard</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/EINA conference/plugin/chalkboard"><li><li><a href="../../public_notes/export/EINA-conference/plugin/chalkboard/README" data-for="public_notes/export/EINA-conference/plugin/chalkboard/README">README</a></li></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/EINA conference/plugin/chart"><button class="folder-button"><p class="folder-title">chart</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/EINA conference/plugin/chart"><li><li><a href="../../public_notes/export/EINA-conference/plugin/chart/README" data-for="public_notes/export/EINA-conference/plugin/chart/README">README</a></li></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/EINA conference/plugin/customcontrols"><button class="folder-button"><p class="folder-title">customcontrols</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/EINA conference/plugin/customcontrols"><li><li><a href="../../public_notes/export/EINA-conference/plugin/customcontrols/README" data-for="public_notes/export/EINA-conference/plugin/customcontrols/README">README</a></li></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/export/EINA conference/plugin/menu"><button class="folder-button"><p class="folder-title">menu</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/export/EINA conference/plugin/menu"><li><li><a href="../../public_notes/export/EINA-conference/plugin/menu/CONTRIBUTING" data-for="public_notes/export/EINA-conference/plugin/menu/CONTRIBUTING">CONTRIBUTING</a></li></li><li><li><a href="../../public_notes/export/EINA-conference/plugin/menu/README" data-for="public_notes/export/EINA-conference/plugin/menu/README">README</a></li></li></ul></div></div></li></ul></div></div></li></ul></div></div></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/Sculpting Time with Computers"><button class="folder-button"><p class="folder-title">Sculpting Time with Computers</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/Sculpting Time with Computers"><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/List-of-all-notes" data-for="public_notes/Sculpting-Time-with-Computers/List-of-all-notes">a list of all notes here</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Andrea-Farina" data-for="public_notes/Sculpting-Time-with-Computers/Andrea-Farina">Andrea Farina</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Annotation-guidelines" data-for="public_notes/Sculpting-Time-with-Computers/Annotation-guidelines">Annotation guidelines</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Belén-Vidal" data-for="public_notes/Sculpting-Time-with-Computers/Belén-Vidal">Belén Vidal</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Carlo-Bretti" data-for="public_notes/Sculpting-Time-with-Computers/Carlo-Bretti">Carlo Bretti</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/cinematic-time" data-for="public_notes/Sculpting-Time-with-Computers/cinematic-time">cinematic time</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/collections" data-for="public_notes/Sculpting-Time-with-Computers/collections">collections</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/computational" data-for="public_notes/Sculpting-Time-with-Computers/computational">computational</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/day-one" data-for="public_notes/Sculpting-Time-with-Computers/day-one">day one</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/day-two" data-for="public_notes/Sculpting-Time-with-Computers/day-two">day two</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/design" data-for="public_notes/Sculpting-Time-with-Computers/design">design</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/film" data-for="public_notes/Sculpting-Time-with-Computers/film">film</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/High-dimensional-Cinema" data-for="public_notes/Sculpting-Time-with-Computers/High-dimensional-Cinema">High-dimensional Cinema</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/high-level-reasoning-about-time" data-for="public_notes/Sculpting-Time-with-Computers/high-level-reasoning-about-time">high-level reasoning about time</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/historical-time" data-for="public_notes/Sculpting-Time-with-Computers/historical-time">historical time</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/ideas-and-next-steps" data-for="public_notes/Sculpting-Time-with-Computers/ideas-and-next-steps">ideas and next steps</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Isadora-Campregher" data-for="public_notes/Sculpting-Time-with-Computers/Isadora-Campregher">Isadora Campregher</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Jake-Berger" data-for="public_notes/Sculpting-Time-with-Computers/Jake-Berger">Jake Berger</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Joel-McKim" data-for="public_notes/Sculpting-Time-with-Computers/Joel-McKim">Joel McKim</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/long-list-of-ideas" data-for="public_notes/Sculpting-Time-with-Computers/long-list-of-ideas">long list of ideas</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Mila-Oiva" data-for="public_notes/Sculpting-Time-with-Computers/Mila-Oiva">Mila Oiva</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Nanne-van-Noord" data-for="public_notes/Sculpting-Time-with-Computers/Nanne-van-Noord">Nanne van Noord</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Participants" data-for="public_notes/Sculpting-Time-with-Computers/Participants">Participants</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Pauline-van-Mourik-Broekman" data-for="public_notes/Sculpting-Time-with-Computers/Pauline-van-Mourik-Broekman">Pauline van Mourik Broekman</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Reverse-compression-as-motion-estimation" data-for="public_notes/Sculpting-Time-with-Computers/Reverse-compression-as-motion-estimation">Reverse compression as motion estimation</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Sculpting-Time-With-Computers" data-for="public_notes/Sculpting-Time-with-Computers/Sculpting-Time-With-Computers">Sculpting Time with Computers</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Stephen-McConnachie" data-for="public_notes/Sculpting-Time-with-Computers/Stephen-McConnachie">Stephen McConnachie</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/subjective-time" data-for="public_notes/Sculpting-Time-with-Computers/subjective-time">subjective time</a></li></li><li><li><a href="../../public_notes/Sculpting-Time-with-Computers/Tom-Brown" data-for="public_notes/Sculpting-Time-with-Computers/Tom-Brown">Tom Brown</a></li></li></ul></div></div></li><li><div><div class="folder-container"><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="5 8 14 8" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="folder-icon"><polyline points="6 9 12 15 18 9"></polyline></svg><div data-folderpath="/public_notes/Tools"><button class="folder-button"><p class="folder-title">Tools</p></button></div></div><div class="folder-outer "><ul style="padding-left:1.4rem;" class="content" data-folderul="/public_notes/Tools"><li><li><a href="../../public_notes/Tools/Mermaid-diagrams" data-for="public_notes/Tools/Mermaid-diagrams">Mermaid diagrams</a></li></li><li><li><a href="../../public_notes/Tools/Motion-Canvas" data-for="public_notes/Tools/Motion-Canvas">Motion Canvas</a></li></li><li><li><a href="../../public_notes/Tools/Movie-Barcodes" data-for="public_notes/Tools/Movie-Barcodes">Movie Barcodes</a></li></li><li><li><a href="../../public_notes/Tools/Streaming-Video-Model" data-for="public_notes/Tools/Streaming-Video-Model">Streaming Video Model</a></li></li><li><li><a href="../../public_notes/Tools/Videogrep" data-for="public_notes/Tools/Videogrep">Videogrep</a></li></li><li><li><a href="../../public_notes/Tools/Zeeschuimer" data-for="public_notes/Tools/Zeeschuimer">Zeeschuimer</a></li></li></ul></div></div></li><li><li><a href="../../public_notes/5-principles-of-life" data-for="public_notes/5-principles-of-life">5 principles of life</a></li></li><li><li><a href="../../public_notes/Cinema-and-Machine-Vision" data-for="public_notes/Cinema-and-Machine-Vision">Cinema and Machine Vision</a></li></li><li><li><a href="../../public_notes/Creanalytics" data-for="public_notes/Creanalytics">Creanalytics</a></li></li><li><li><a href="../../public_notes/Creative-AI-Theory-and-Practice" data-for="public_notes/Creative-AI-Theory-and-Practice">Creative AI Theory and Practice</a></li></li><li><li><a href="../../public_notes/Human-centered-machine-vision-q" data-for="public_notes/Human-centered-machine-vision-q">Human-centered machine vision?</a></li></li><li><li><a href="../../public_notes/Cultural-Metabolism-and-LLMs-on-wheels" data-for="public_notes/Cultural-Metabolism-and-LLMs-on-wheels">NYU - Prague</a></li></li><li><li><a href="../../public_notes/small-large-LLMs" data-for="public_notes/small-large-LLMs">small large LLMs</a></li></li><li><li><a href="../../public_notes/The-Digital-Pastoral" data-for="public_notes/The-Digital-Pastoral">The Digital Pastoral</a></li></li><li><li><a href="../../public_notes/Transmediale-2023" data-for="public_notes/Transmediale-2023">Transmediale 2023</a></li></li><li><li><a href="../../public_notes/Video-as-data" data-for="public_notes/Video-as-data">Video as data in the US</a></li></li><li><li><a href="../../public_notes/Video-understanding-community" data-for="public_notes/Video-understanding-community">Video-understanding community</a></li></li></ul></div></div></li><li><li><a href="../../" data-for="index">📝 Daniel's Notes.</a></li></li></ul></div></div></li><li id="explorer-end"></li></ul></div></div></div><div class="center"><div class="page-header"><div class="popover-hint"><nav class="breadcrumb-container " aria-label="breadcrumbs"><div class="breadcrumb-element"><a href="../../">Home</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../public_notes/">public_notes</a><p> ❯ </p></div><div class="breadcrumb-element"><a href="../../public_notes/EPFL-symposium/">EPFL symposium</a><p> ❯ </p></div><div class="breadcrumb-element"><a href>Creanalytics</a></div></nav><h1 class="article-title ">Creanalytics</h1><p class="content-meta ">Dec 03, 2023, 10 min read</p><ul class="tags "><li><a href="../../tags/presentation" class="internal tag-link">#presentation</a></li></ul></div></div><article class="popover-hint"><h1 id="creanalytics">Creanalytics<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#creanalytics" class="internal alias"> §</a></h1>
<h3 id="between-data-analysis-and-media-synthesis"><em>Between Data Analysis and Media Synthesis</em><a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#between-data-analysis-and-media-synthesis" class="internal alias"> §</a></h3>
<p>Dr Daniel Chávez Heras</p>
<p><img src="../../assets/images/db3a81949ab652d55054d76b287e03fa_MD5.jpg" width="250" height="auto"/></p>
<p><a href="https://sigmoid.social/@chavezheras" class="external alias">@chavezheras@sigmoid.social</a></p>
<p><a href="https://movingpixel.net/" class="external alias">movingpixel.net</a></p>
<p>note: Thank you for the invitation, delighted to be here.</p>
<hr/>
<p><img src="../../assets/images/183e9e0918ae84bbdba0e566dd06a5e7_MD5.jpg" width="auto" height="auto"/></p>
<p>note:
A project in 2018 to “machine-see” the BBC television archive, and “machine-edit” new sequences “television by the meter” ―we jokingly referred to it.</p>
<p>Aired on BBC 4 on September 2018, seen by half a million people in the UK.
It included four sections that corresponded to different computational techniques to traverse the archive: including text analysis over subtitled material, object detection, motion estimation (visual energy), and a mixed between the three (what we would call today a multimodal method).</p>
<hr/>
<iframe src="https://player.vimeo.com/video/429123167?h=a9f1da53da" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
<p><a href="https://vimeo.com/429123167" class="external alias">2. MbM: Object Detection</a> from <a href="https://vimeo.com/chavezheras" class="external alias">Daniel Chávez Heras</a> on <a href="https://vimeo.com" class="external alias">Vimeo</a>.</p>
note:
This was a project in experimental television, in hindsight it was very much of its time, and frankly, as time goes by I am more and more surprised that no one stopped us from doing it. 
<p>In light of everything that happened after with AI, this project stands a somewhat of a quaint expression of many of the issues discussed yesterday, from access and copyright, to the role of generative technologies and their impact on screen culture today.</p>
<hr/>
<h2 id="an-epistemic-gap-between-archives-and-datasets">An epistemic gap between archives and datasets<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#an-epistemic-gap-between-archives-and-datasets" class="internal alias"> §</a></h2>
<h2 id="a-functional-proximity-between-data-analysis-and-media-synthesis">A functional proximity between data analysis and media synthesis<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#a-functional-proximity-between-data-analysis-and-media-synthesis" class="internal alias"> §</a></h2>
<p>note:</p>
<p>In this talk I want to highlight two key insights I gained from this project:</p>
<p>By this I mean the gap between how it is that AI systems contribute to the production of knowledge, what kinds of knowledge, and how this knowledge might be valuable for the understanding of moving images. And how this is radically different from how moving image archives contribute to knowledge and produce value to the societies that keep them.</p>
<p>By this I mean the rather unexpected way in which scientific and creative computing are entangled in generative AI systems.</p>
<p>I will spend a couple of slides on the first point, because I think most of this ground has been covered in one way or another yesterday, and spend some more time on the second premise, including examples.</p>
<hr/>
<h2 id="archives-and-datasets">Archives and Datasets<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#archives-and-datasets" class="internal alias"> §</a></h2>
<p><img src="../../assets/images/eye_film_installation.jpg" width="1000" height="auto"/></p>
<p>note:
Archives are made for humans, datasets are by humans for machines.</p>
<p>Oversimplification: we know machines are made by and for humans too, but still, the purpose of their</p>
<p>Archives are created under a historical impulse; they are organised according to the record-keeping needs of the cultures that build them. This historical impulse requires system that facilitates cataloguing and retrieval, and that aspires to a certain degree of historical accuracy, integrity, and permanence.</p>
<p>Datasets also respond to the sense-making needs of the cultures that build them, but they come together to lay claim on the future more than the past, usually in response to specific problems and questions that need solving, which is to say they are much more instrumental.</p>
<p>In data science and machine learning engineering, datasets tend to be granular, flattened to matrix-like structures whose individual items are not meant to be publicly accessible or even individually meaningful to human observers.</p>
<p>Arguably, contemporary AI has succeeded precisely for not caring at all about whether specific media artefacts are deemed significant enough to go ‘on the record’, and be keept for posterity, with all the cost implications that this kind of collective memory keeping entails, but because of the opposite approach, by voraciously ingesting heaps of data that in themselves were not canonical or significant.</p>
<p>I would got a step further still, and say that archives and datasets produce value in almost opposite ways: while archives endow their constituent artefacts and records with additional symbolic layers, making them stable and tractable, datasets that feed contemporary AI systems atomise these artefacts, stripping them from context in order to make patterns visible through computational processing. In the first case value is produced by stability and addressability, in the second by aggregation and mutability.</p>
<p>—</p>
<h2 id="data-palimpsests">Data palimpsests<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#data-palimpsests" class="internal alias"> §</a></h2>








































<div class="table-container"><table><thead><tr><th>Artefact</th><th>Processing level</th><th>Example</th></tr></thead><tbody><tr><td>Cinema</td><td>Social – aggregate</td><td>Popular Hollywood cinema</td></tr><tr><td>Film</td><td>Human</td><td>Jurassic Park (1993)</td></tr><tr><td>Clip</td><td>Human/computer</td><td>Raptors in the Kitchen Scene (<a href="https://youtu.be/dnRxQ3dcaQk" class="external">https://youtu.be/dnRxQ3dcaQk</a>)</td></tr><tr><td>Shot</td><td>Human-computer</td><td>130 frames (5.421 s)</td></tr><tr><td>Frame</td><td>Computer/human</td><td>Individual frame (512 × 340 pixels)</td></tr><tr><td>Pixels</td><td>Numeric – disaggregate</td><td>Vector ([176800x1]); Tensor ([16, 3, 340, 512])</td></tr></tbody></table></div>
<p>note:</p>
<p>Yet, there is a relation between archives and datasets.
Each of the films contained in a film archive can be thought of a dataset of frames, and every frame as dataset of pixels.  Through computing, individual frames and their pixels can relate much more freely, not only to other frames in the same film, but to a multitude of other frames in a multitude of other films, in high-dimensional spaces where every pixel might be put in contact with any other.</p>
<p>This table exemplifies the palimpsest of artefacts and levels of analysis at play between audiovisual archives, comprised of artefacts, and datasets atomised for machine learning operations. The epistemic gap between the two ends of the table are yet to be fully understood in the configuration of a computational archive.</p>
<hr/>
<h2 id="data-analysis-and-media-synthesis">Data Analysis and Media Synthesis<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#data-analysis-and-media-synthesis" class="internal alias"> §</a></h2>
<p><img src="../../assets/images/CSN_newsreels_1.png" width="1000" height="auto"/></p>
<p>note:</p>
<p>Analytic and generative approaches in computing tend to be split between scientific and creative domains, with their respective tools and communities of practice.</p>
<p>Deployed as analytical engines, computers can be used to find patterns across vast collections of imagery, and these patterns are often expressed as relations of proximity in space. We have seen examples of this yesterday in multiple way of projecting archives onto 2d or 3d spaces.</p>
<p>The image in this slide shows a t-SNE mapping of a collection of soviet news reels. The dataset and the tool were developed by colleagues in CUDAN from the cultural data analytics lab in Tallinn, Estonia.</p>
<p>But to amount to knowledge, these spatial correlations require interpretation and explanation, which require relations of necessity, not just proximity, and tend to unfold sequentially, as researchers, critics and users seek to organise these patterns to infer causal relations and plausible reasons for data objects and events to be organised in space the way they are.</p>
<p>By coupling an analytical engine with a generative one, computing can be used to configure narratives about these proximity patterns and enable explanatory propositions through compositional techniques familiar to media scholarship.</p>
<p>—</p>
<h2 id="supercuts">Supercuts<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#supercuts" class="internal alias"> §</a></h2>
<blockquote>
<p>Just as capitalism treated workers as machines as a prelude to workers being replaced by machines, so also supercutters simulate database thinking in apparent anticipation of a moment, perhaps in the near future, when <strong>neural networks will be able to search the entirety of digitized film history and create supercuts themselves, automatically</strong>.</p>
</blockquote>
<p>- Max Tohline, 2021</p>
<blockquote>
<p>In the near future there will be a simple software or app, feeding its algorithm with keywords and other elements of interest, which will <strong>automatically generate a perfect supercut of media content of any kind within a blink of an eye</strong>.</p>
</blockquote>
<p>- Miklós Kiss, 2013</p>
<p>note:</p>
<p>a supercut is an editing technique in which short video clips with common motifs or salient stylistic characteristics are extracted from their original context and are sequenced together in a montage. The commonalities are highlighted through repetition and interpreted by viewers as a form of <em>aboutness</em>, which then becomes the thematic content of the supercut.</p>
<p>The supercut entails not simply a mode of editing, but a mode of thinking expressed by a mode of editing.</p>
<p>—</p>
<h2 id="computational-supercuts">Computational supercuts<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#computational-supercuts" class="internal alias"> §</a></h2>
<iframe title="vimeo-player" src="https://player.vimeo.com/video/830237949?h=5fb9301c4d" width="640" height="360" frameborder="0" allowfullscreen></iframe>
<p>note:
This was made using a tool called VGREP, developed by artist and creative coder Sam Lavigne as part of a small project funded through a small grant I got last year to explore computational media formats.</p>
<p>The tool takes a video file as an input, transcribes its dialogue, and then analyses the text to find common ngrams. These can then selected and edited as a supercut.</p>
<p>The lecture was called “Modeling Doubt, Coding Humility” and through this technique I found there were many more mentions of doubt than of coding or humility (the lecture however was ver good).</p>
<p>I wanted to take this idea a step forward and see if a similar effect could be achieved by operating directly on the images, automating a supercut of visual characteristics.</p>
<p>—</p>
<h2 id="movie-clips-youtube-channel">Movie Clips YouTube channel<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#movie-clips-youtube-channel" class="internal alias"> §</a></h2>
<p> <img src="../../assets/images/e3ee5592f9728d7d204e90a475a2a42f_MD5.jpg" width="auto" height="auto"/></p>
<p>note:
An archive-like collection that is publicly available online: the <em>Movieclips</em> YouTube channel (<a href="https://journals.sagepub.com/doi/full/10.1177/13548565231174592#bibr29-13548565231174592" class="external alias">2006</a>), which serves as a corpus that is both large and consistent enough to be analysed and intervened using computational methods.</p>
<p>This channel is operated by the American media company <em>Fandango</em>, which owns the popular review aggregator website <em>Rotten Tomatoes</em>, and the recommender platform <em>Flixter</em>, and which is itself jointly owned by the Warner and Universal media conglomerates.</p>
<p>In their YouTube channel <em>Movieclips</em> is described as ‘the largest collection of licensed movie clips on the web’. At the time of writing, it had over 58 million subscribers and almost 60 billion aggregated views.</p>
<p>In terms of access, these numbers dwarf most film archives, but it is important to note that in terms of breadth and diversity, these movie clips are only one deep but thin slice of global film production, namely, recent Hollywood popular cinema licenced by these large media companies.</p>
<p>—</p>
<h2 id="movie-clips-corpus">Movie Clips Corpus<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#movie-clips-corpus" class="internal alias"> §</a></h2>
<ul>
<li>2691 clips</li>
<li>350 films</li>
<li>From 1931 to 2019</li>
<li>287 unique directors</li>
</ul>
<p>—</p>
<h2 id="pre-trained-fer-detection">Pre-trained FER detection<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pre-trained-fer-detection" class="internal alias"> §</a></h2>
<p><img src="../../assets/images/ladybird_FER_1.jpeg" width="1000" height="auto"/></p>
<p>—</p>
<h2 id="shot-scale-detector">Shot scale detector<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#shot-scale-detector" class="internal alias"> §</a></h2>
<p><img src="../../assets/images/schot_scale_detector.jpg" width="1000" height="auto"/></p>
<p>—</p>
<h2 id="feature-engineering">Feature Engineering<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#feature-engineering" class="internal alias"> §</a></h2>





































<div class="table-container"><table><thead><tr><th align="left">Feature</th><th align="left">Value</th></tr></thead><tbody><tr><td align="left">People</td><td align="left">1</td></tr><tr><td align="left">Scale</td><td align="left">23.2</td></tr><tr><td align="left">Inferred motion</td><td align="left">0.24</td></tr><tr><td align="left">Scale category</td><td align="left">‘CU’</td></tr><tr><td align="left">Inferred motion category</td><td align="left">‘Stable’</td></tr><tr><td align="left">Top emotion</td><td align="left">‘Angry’</td></tr><tr><td align="left">Top emotion confidence</td><td align="left">0.79</td></tr></tbody></table></div>
<p>—</p>
<h2 id="shot-duration-distribution">Shot duration distribution<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#shot-duration-distribution" class="internal alias"> §</a></h2>
<p><img src="../../assets/images/shot_histogram.jpeg" width="1200" height="auto"/></p>
<p>note:
conventional statistics give overview of this dataset of shots</p>
<p>—</p>
<h2 id="shot-scale-breakdown">Shot scale breakdown<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#shot-scale-breakdown" class="internal alias"> §</a></h2>
<p><img src="../../assets/images/shot_scale_chart.jpeg" width="1200" height="auto"/></p>
<p>note:
more sophisticated tools to do this now, like Cineshot deep learning method to find shot scale in films</p>
<p>—</p>
<h2 id="shot-emotion-breakdown">Shot emotion breakdown<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#shot-emotion-breakdown" class="internal alias"> §</a></h2>
<p><img src="../../assets/images/shot_emotion_chart.jpeg" width="1200" height="auto"/></p>
<p>note:
the obvious caveats of this is the simplification of emotions to few categories, an approach that has been criticised and widely updated in psychology.</p>
<p>—</p>
<h2 id="shot-scale-supercut">shot scale supercut<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#shot-scale-supercut" class="internal alias"> §</a></h2>
<iframe src="https://player.vimeo.com/video/602000956?h=71ac4fdc22" width="640" height="360" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen></iframe>
<p><a href="https://vimeo.com/602000956" class="external alias">Big Angry Faces v.01</a> from <a href="https://vimeo.com/chavezheras" class="external alias">Daniel Chávez Heras</a> on <a href="https://vimeo.com" class="external alias">Vimeo</a>.</p>
<p>note:
On the one  hand the computational supercut involves applying computer vision methods to annotate large collections of moving images to find patterns, much in the guise of cultural analytics.</p>
<p>But on the other, as well as plotting these images in space to view them at a distance, to make sense of them we need to reinscribe these patterns in time, giving data objects a duration again, and enabling interpretation through the familiar operations of montage and the syntactic and synoptic apparatus of (dis)continuity as a modality for meaning making and explanation.</p>
<p>The kind of reverse editing proposed in the computational supercut links in this way analytical and creative epistemic strategies: knowledge and value created through the making and unmaking of moving imagery; visual culture that feeds AI that feeds back into visual culture.>)</p>
<p>—</p>
<p><img src="../../assets/images/computational_supercuts.png" width="1200" height="auto"/></p>
<p>note:</p>
<p>I have experimented further with this type of parametric sampling/editing, and some of these experiments can be found online. If there is enough interest I might develop the technique further and might distribute it as a tool that can be used in other collections.</p>
<p>—</p>
<h2 id="continuity-matrix-noël-burch">Continuity Matrix (Noël Burch)<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#continuity-matrix-noël-burch" class="internal alias"> §</a></h2>





































<div class="table-container"><table><thead><tr><th><strong>Time</strong>/<strong>Space</strong></th><th><strong>Continuous</strong></th><th><strong>Ellipsis (definite)</strong></th><th><strong>Ellipsis (indefinite)</strong></th><th><strong>Time reversal (definite)</strong></th><th><strong>Time reversal (indefinite)</strong></th></tr></thead><tbody><tr><td>Continuous</td><td>CC</td><td>CE</td><td>CEi</td><td>CR</td><td>CRi</td></tr><tr><td>Contiguous</td><td>CtC</td><td>CtE</td><td>CtEi</td><td>CtR</td><td>CtRi</td></tr><tr><td>Discontinuous</td><td>DC</td><td>DE</td><td>DEi</td><td>DR</td><td>DRi</td></tr></tbody></table></div>
<p>note:
But we know we make sense of images not only by what is shown on screen, but by what is omitted. Arguably, films convey as much meaning through time elision than they do through time recording.</p>
<p>Therefore, in order to model a “computational Burch” we need both the edit points that separate one shot from the next <em>and</em> an annotation of what viewers infer to be in-between the shots. This second signal is much more elusive because it needs to be encoded form a subjective unconscious process that appears to leave no traces.</p>
<p>—</p>
<p><img src="../../assets/images/godfather_continuity.png" width="auto" height="auto"/></p>
<p>—</p>
<p><img src="../../assets/images/burch_continuity_1.png" width="auto" height="auto"/></p>
<p>—</p>
<p><img src="../../assets/images/burch_continuity_2.png" width="auto" height="auto"/></p>
<p>note:
Note that while the patterns above reflect the parallel editing technique in this sequence, they are not representations of the shots themselves, but of the relations between them as inferred by a viewer; the subjective invisible that makes the objective visible meaningful.</p>
<hr/>
<h1 id="moving-image-archive-of-the-future">Moving image archive of the future<a aria-hidden="true" tabindex="-1" data-no-popover="true" href="#moving-image-archive-of-the-future" class="internal alias"> §</a></h1>
<ul>
<li>Create and recreate the archive</li>
<li>Play the archive</li>
</ul>
<p>note:</p>
<ul>
<li>Structurally similar to a system of systems</li>
<li>Accessed through narrative forms of interaction</li>
<li>Shaped and reshaped on demand
<ul>
<li>access different versions of the archive, and simulate what might have been under different circumstances</li>
<li>play (reproduce) the archive, as if it were a larger form of media</li>
</ul>
</li>
</ul>
<hr/>
<p><img src="../../assets/images/book_and_article_2.png" width="auto" height="auto"/></p>
<p>note:</p></article></div><div class="right sidebar"><div class="graph "><h3>Graph View</h3><div class="graph-outer"><div id="graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:1,&quot;scale&quot;:1.1,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[]}"></div><svg version="1.1" id="global-graph-icon" xmlns="http://www.w3.org/2000/svg" xmlnsXlink="http://www.w3.org/1999/xlink" x="0px" y="0px" viewBox="0 0 55 55" fill="currentColor" xmlSpace="preserve"><path d="M49,0c-3.309,0-6,2.691-6,6c0,1.035,0.263,2.009,0.726,2.86l-9.829,9.829C32.542,17.634,30.846,17,29,17
	s-3.542,0.634-4.898,1.688l-7.669-7.669C16.785,10.424,17,9.74,17,9c0-2.206-1.794-4-4-4S9,6.794,9,9s1.794,4,4,4
	c0.74,0,1.424-0.215,2.019-0.567l7.669,7.669C21.634,21.458,21,23.154,21,25s0.634,3.542,1.688,4.897L10.024,42.562
	C8.958,41.595,7.549,41,6,41c-3.309,0-6,2.691-6,6s2.691,6,6,6s6-2.691,6-6c0-1.035-0.263-2.009-0.726-2.86l12.829-12.829
	c1.106,0.86,2.44,1.436,3.898,1.619v10.16c-2.833,0.478-5,2.942-5,5.91c0,3.309,2.691,6,6,6s6-2.691,6-6c0-2.967-2.167-5.431-5-5.91
	v-10.16c1.458-0.183,2.792-0.759,3.898-1.619l7.669,7.669C41.215,39.576,41,40.26,41,41c0,2.206,1.794,4,4,4s4-1.794,4-4
	s-1.794-4-4-4c-0.74,0-1.424,0.215-2.019,0.567l-7.669-7.669C36.366,28.542,37,26.846,37,25s-0.634-3.542-1.688-4.897l9.665-9.665
	C46.042,11.405,47.451,12,49,12c3.309,0,6-2.691,6-6S52.309,0,49,0z M11,9c0-1.103,0.897-2,2-2s2,0.897,2,2s-0.897,2-2,2
	S11,10.103,11,9z M6,51c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S8.206,51,6,51z M33,49c0,2.206-1.794,4-4,4s-4-1.794-4-4
	s1.794-4,4-4S33,46.794,33,49z M29,31c-3.309,0-6-2.691-6-6s2.691-6,6-6s6,2.691,6,6S32.309,31,29,31z M47,41c0,1.103-0.897,2-2,2
	s-2-0.897-2-2s0.897-2,2-2S47,39.897,47,41z M49,10c-2.206,0-4-1.794-4-4s1.794-4,4-4s4,1.794,4,4S51.206,10,49,10z"></path></svg></div><div id="global-graph-outer"><div id="global-graph-container" data-cfg="{&quot;drag&quot;:true,&quot;zoom&quot;:true,&quot;depth&quot;:-1,&quot;scale&quot;:0.9,&quot;repelForce&quot;:0.5,&quot;centerForce&quot;:0.3,&quot;linkDistance&quot;:30,&quot;fontSize&quot;:0.6,&quot;opacityScale&quot;:1,&quot;showTags&quot;:true,&quot;removeTags&quot;:[]}"></div></div></div><div class="toc desktop-only"><button type="button" id="toc" class><h3>Table of Contents</h3><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="fold"><polyline points="6 9 12 15 18 9"></polyline></svg></button><div id="toc-content"><ul class="overflow"><li class="depth-0"><a href="#creanalytics" data-for="creanalytics">Creanalytics</a></li><li class="depth-2"><a href="#between-data-analysis-and-media-synthesis" data-for="between-data-analysis-and-media-synthesis">Between Data Analysis and Media Synthesis</a></li><li class="depth-1"><a href="#an-epistemic-gap-between-archives-and-datasets" data-for="an-epistemic-gap-between-archives-and-datasets">An epistemic gap between archives and datasets</a></li><li class="depth-1"><a href="#a-functional-proximity-between-data-analysis-and-media-synthesis" data-for="a-functional-proximity-between-data-analysis-and-media-synthesis">A functional proximity between data analysis and media synthesis</a></li><li class="depth-1"><a href="#archives-and-datasets" data-for="archives-and-datasets">Archives and Datasets</a></li><li class="depth-1"><a href="#data-palimpsests" data-for="data-palimpsests">Data palimpsests</a></li><li class="depth-1"><a href="#data-analysis-and-media-synthesis" data-for="data-analysis-and-media-synthesis">Data Analysis and Media Synthesis</a></li><li class="depth-1"><a href="#supercuts" data-for="supercuts">Supercuts</a></li><li class="depth-1"><a href="#computational-supercuts" data-for="computational-supercuts">Computational supercuts</a></li><li class="depth-1"><a href="#movie-clips-youtube-channel" data-for="movie-clips-youtube-channel">Movie Clips YouTube channel</a></li><li class="depth-1"><a href="#movie-clips-corpus" data-for="movie-clips-corpus">Movie Clips Corpus</a></li><li class="depth-1"><a href="#pre-trained-fer-detection" data-for="pre-trained-fer-detection">Pre-trained FER detection</a></li><li class="depth-1"><a href="#shot-scale-detector" data-for="shot-scale-detector">Shot scale detector</a></li><li class="depth-1"><a href="#feature-engineering" data-for="feature-engineering">Feature Engineering</a></li><li class="depth-1"><a href="#shot-duration-distribution" data-for="shot-duration-distribution">Shot duration distribution</a></li><li class="depth-1"><a href="#shot-scale-breakdown" data-for="shot-scale-breakdown">Shot scale breakdown</a></li><li class="depth-1"><a href="#shot-emotion-breakdown" data-for="shot-emotion-breakdown">Shot emotion breakdown</a></li><li class="depth-1"><a href="#shot-scale-supercut" data-for="shot-scale-supercut">shot scale supercut</a></li><li class="depth-1"><a href="#continuity-matrix-noël-burch" data-for="continuity-matrix-noël-burch">Continuity Matrix (Noël Burch)</a></li><li class="depth-0"><a href="#moving-image-archive-of-the-future" data-for="moving-image-archive-of-the-future">Moving image archive of the future</a></li></ul></div></div><div class="backlinks "><h3>Backlinks</h3><ul class="overflow"><li>No backlinks found</li></ul></div></div></div><footer class><hr/><p>Created with <a href="https://quartz.jzhao.xyz/">Quartz v4.1.2</a>, © 2023</p><ul><li><a href="https://github.com/jackyzha0/quartz">GitHub</a></li><li><a href="https://discord.gg/cRFFHYye7t">Discord Community</a></li></ul></footer></div></body><script type="application/javascript">// quartz/components/scripts/quartz/components/scripts/callout.inline.ts
function toggleCallout() {
  const outerBlock = this.parentElement;
  outerBlock.classList.toggle(`is-collapsed`);
  const collapsed = outerBlock.classList.contains(`is-collapsed`);
  const height = collapsed ? this.scrollHeight : outerBlock.scrollHeight;
  outerBlock.style.maxHeight = height + `px`;
  let current = outerBlock;
  let parent = outerBlock.parentElement;
  while (parent) {
    if (!parent.classList.contains(`callout`)) {
      return;
    }
    const collapsed2 = parent.classList.contains(`is-collapsed`);
    const height2 = collapsed2 ? parent.scrollHeight : parent.scrollHeight + current.scrollHeight;
    parent.style.maxHeight = height2 + `px`;
    current = parent;
    parent = parent.parentElement;
  }
}
function setupCallout() {
  const collapsible = document.getElementsByClassName(
    `callout is-collapsible`
  );
  for (const div of collapsible) {
    const title = div.firstElementChild;
    if (title) {
      title.removeEventListener(`click`, toggleCallout);
      title.addEventListener(`click`, toggleCallout);
      const collapsed = div.classList.contains(`is-collapsed`);
      const height = collapsed ? title.scrollHeight : div.scrollHeight;
      div.style.maxHeight = height + `px`;
    }
  }
}
document.addEventListener(`nav`, setupCallout);
window.addEventListener(`resize`, setupCallout);
</script><script type="module">
          import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid/dist/mermaid.esm.min.mjs';
          const darkMode = document.documentElement.getAttribute('saved-theme') === 'dark'
          mermaid.initialize({
            startOnLoad: false,
            securityLevel: 'loose',
            theme: darkMode ? 'dark' : 'default'
          });
          document.addEventListener('nav', async () => {
            await mermaid.run({
              querySelector: '.mermaid'
            })
          });
          </script><script src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/copy-tex.min.js" type="application/javascript"></script><script type="application/javascript">
          const socket = new WebSocket('ws://localhost:3001')
          socket.addEventListener('message', () => document.location.reload())
        </script><script src="../../postscript.js" type="module"></script></html>